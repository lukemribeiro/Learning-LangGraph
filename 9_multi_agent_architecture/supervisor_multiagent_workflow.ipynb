{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-experimental\n",
      "  Downloading langchain_experimental-0.3.4-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: langchain-community<0.4.0,>=0.3.0 in /Users/lukeribeiro/work/langgraph-mini-course/.venv/lib/python3.11/site-packages (from langchain-experimental) (0.3.29)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.28 in /Users/lukeribeiro/work/langgraph-mini-course/.venv/lib/python3.11/site-packages (from langchain-experimental) (0.3.76)\n",
      "Requirement already satisfied: langchain<2.0.0,>=0.3.27 in /Users/lukeribeiro/work/langgraph-mini-course/.venv/lib/python3.11/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (0.3.27)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/lukeribeiro/work/langgraph-mini-course/.venv/lib/python3.11/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (2.0.43)\n",
      "Requirement already satisfied: requests<3,>=2.32.5 in /Users/lukeribeiro/work/langgraph-mini-course/.venv/lib/python3.11/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (2.32.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/lukeribeiro/work/langgraph-mini-course/.venv/lib/python3.11/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/lukeribeiro/work/langgraph-mini-course/.venv/lib/python3.11/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (3.12.15)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /Users/lukeribeiro/work/langgraph-mini-course/.venv/lib/python3.11/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.6.7 in /Users/lukeribeiro/work/langgraph-mini-course/.venv/lib/python3.11/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /Users/lukeribeiro/work/langgraph-mini-course/.venv/lib/python3.11/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (2.10.1)\n",
      "Requirement already satisfied: langsmith>=0.1.125 in /Users/lukeribeiro/work/langgraph-mini-course/.venv/lib/python3.11/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (0.4.27)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /Users/lukeribeiro/work/langgraph-mini-course/.venv/lib/python3.11/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /Users/lukeribeiro/work/langgraph-mini-course/.venv/lib/python3.11/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental) (2.3.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/lukeribeiro/work/langgraph-mini-course/.venv/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.28->langchain-experimental) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/lukeribeiro/work/langgraph-mini-course/.venv/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.28->langchain-experimental) (4.15.0)\n",
      "Requirement already satisfied: packaging>=23.2 in /Users/lukeribeiro/work/langgraph-mini-course/.venv/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.28->langchain-experimental) (25.0)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /Users/lukeribeiro/work/langgraph-mini-course/.venv/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.28->langchain-experimental) (2.11.8)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/lukeribeiro/work/langgraph-mini-course/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/lukeribeiro/work/langgraph-mini-course/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/lukeribeiro/work/langgraph-mini-course/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/lukeribeiro/work/langgraph-mini-course/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/lukeribeiro/work/langgraph-mini-course/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/lukeribeiro/work/langgraph-mini-course/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/lukeribeiro/work/langgraph-mini-course/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/lukeribeiro/work/langgraph-mini-course/.venv/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.6.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/lukeribeiro/work/langgraph-mini-course/.venv/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.6.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/lukeribeiro/work/langgraph-mini-course/.venv/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.28->langchain-experimental) (3.0.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /Users/lukeribeiro/work/langgraph-mini-course/.venv/lib/python3.11/site-packages (from langchain<2.0.0,>=0.3.27->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (0.3.11)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/lukeribeiro/work/langgraph-mini-course/.venv/lib/python3.11/site-packages (from langsmith>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /Users/lukeribeiro/work/langgraph-mini-course/.venv/lib/python3.11/site-packages (from langsmith>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Users/lukeribeiro/work/langgraph-mini-course/.venv/lib/python3.11/site-packages (from langsmith>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /Users/lukeribeiro/work/langgraph-mini-course/.venv/lib/python3.11/site-packages (from langsmith>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (0.24.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/lukeribeiro/work/langgraph-mini-course/.venv/lib/python3.11/site-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.28->langchain-experimental) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/lukeribeiro/work/langgraph-mini-course/.venv/lib/python3.11/site-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.28->langchain-experimental) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/lukeribeiro/work/langgraph-mini-course/.venv/lib/python3.11/site-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.28->langchain-experimental) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /Users/lukeribeiro/work/langgraph-mini-course/.venv/lib/python3.11/site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (1.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/lukeribeiro/work/langgraph-mini-course/.venv/lib/python3.11/site-packages (from requests<3,>=2.32.5->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/lukeribeiro/work/langgraph-mini-course/.venv/lib/python3.11/site-packages (from requests<3,>=2.32.5->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/lukeribeiro/work/langgraph-mini-course/.venv/lib/python3.11/site-packages (from requests<3,>=2.32.5->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/lukeribeiro/work/langgraph-mini-course/.venv/lib/python3.11/site-packages (from requests<3,>=2.32.5->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (2025.8.3)\n",
      "Requirement already satisfied: anyio in /Users/lukeribeiro/work/langgraph-mini-course/.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (4.10.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/lukeribeiro/work/langgraph-mini-course/.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/lukeribeiro/work/langgraph-mini-course/.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (0.16.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/lukeribeiro/work/langgraph-mini-course/.venv/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (1.1.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/lukeribeiro/work/langgraph-mini-course/.venv/lib/python3.11/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental) (1.3.1)\n",
      "Downloading langchain_experimental-0.3.4-py3-none-any.whl (209 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: langchain-experimental\n",
      "Successfully installed langchain-experimental-0.3.4\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain-experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cz/fgv9rks16nbccwjxtgzk0kq00000gn/T/ipykernel_47908/582930312.py:18: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
      "  tavily_search = TavilySearchResults(max_results=2)\n"
     ]
    }
   ],
   "source": [
    "from typing import Annotated, Sequence, List, Literal \n",
    "from pydantic import BaseModel, Field \n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults \n",
    "from langgraph.types import Command \n",
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from langgraph.prebuilt import create_react_agent \n",
    "from IPython.display import Image, display \n",
    "from dotenv import load_dotenv\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "tavily_search = TavilySearchResults(max_results=2)\n",
    "\n",
    "python_repl_tool = PythonREPLTool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'5\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_repl_tool.invoke(\"x = 5; print(x)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Supervisor(BaseModel):\n",
    "    next: Literal[\"enhancer\", \"researcher\", \"coder\"] = Field(\n",
    "        description=\"Determines which specialist to activate next in the workflow sequence: \"\n",
    "                    \"'enhancer' when user input requires clarification, expansion, or refinement, \"\n",
    "                    \"'researcher' when additional facts, context, or data collection is necessary, \"\n",
    "                    \"'coder' when implementation, computation, or technical problem-solving is required.\"\n",
    "    )\n",
    "    reason: str = Field(\n",
    "        description=\"Detailed justification for the routing decision, explaining the rationale behind selecting the particular specialist and how this advances the task toward completion.\"\n",
    "    )\n",
    "\n",
    "def supervisor_node(state: MessagesState) -> Command[Literal[\"enhancer\", \"researcher\", \"coder\"]]:\n",
    "\n",
    "    system_prompt = ('''\n",
    "                 \n",
    "        You are a workflow supervisor managing a team of three specialized agents: Prompt Enhancer, Researcher, and Coder. Your role is to orchestrate the workflow by selecting the most appropriate next agent based on the current state and needs of the task. Provide a clear, concise rationale for each decision to ensure transparency in your decision-making process.\n",
    "\n",
    "        **Team Members**:\n",
    "        1. **Prompt Enhancer**: Always consider this agent first. They clarify ambiguous requests, improve poorly defined queries, and ensure the task is well-structured before deeper processing begins.\n",
    "        2. **Researcher**: Specializes in information gathering, fact-finding, and collecting relevant data needed to address the user's request.\n",
    "        3. **Coder**: Focuses on technical implementation, calculations, data analysis, algorithm development, and coding solutions.\n",
    "\n",
    "        **Your Responsibilities**:\n",
    "        1. Analyze each user request and agent response for completeness, accuracy, and relevance.\n",
    "        2. Route the task to the most appropriate agent at each decision point.\n",
    "        3. Maintain workflow momentum by avoiding redundant agent assignments.\n",
    "        4. Continue the process until the user's request is fully and satisfactorily resolved.\n",
    "\n",
    "        Your objective is to create an efficient workflow that leverages each agent's strengths while minimizing unnecessary steps, ultimately delivering complete and accurate solutions to user requests.\n",
    "                 \n",
    "    ''')\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},  \n",
    "    ] + state[\"messages\"] \n",
    "\n",
    "    response = llm.with_structured_output(Supervisor).invoke(messages)\n",
    "\n",
    "    goto = response.next\n",
    "    reason = response.reason\n",
    "\n",
    "    print(f\"--- Workflow Transition: Supervisor → {goto.upper()} ---\")\n",
    "    \n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=reason, name=\"supervisor\")\n",
    "            ]\n",
    "        },\n",
    "        goto=goto,  \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhancer_node(state: MessagesState) -> Command[Literal[\"supervisor\"]]:\n",
    "\n",
    "    \"\"\"\n",
    "        Enhancer agent node that improves and clarifies user queries.\n",
    "        Takes the original user input and transforms it into a more precise,\n",
    "        actionable request before passing it to the supervisor.\n",
    "    \"\"\"\n",
    "   \n",
    "    system_prompt = (\n",
    "        \"You are a Query Refinement Specialist with expertise in transforming vague requests into precise instructions. Your responsibilities include:\\n\\n\"\n",
    "        \"1. Analyzing the original query to identify key intent and requirements\\n\"\n",
    "        \"2. Resolving any ambiguities without requesting additional user input\\n\"\n",
    "        \"3. Expanding underdeveloped aspects of the query with reasonable assumptions\\n\"\n",
    "        \"4. Restructuring the query for clarity and actionability\\n\"\n",
    "        \"5. Ensuring all technical terminology is properly defined in context\\n\\n\"\n",
    "        \"Important: Never ask questions back to the user. Instead, make informed assumptions and create the most comprehensive version of their request possible.\"\n",
    "    )\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},  \n",
    "    ] + state[\"messages\"]  \n",
    "\n",
    "    enhanced_query = llm.invoke(messages)\n",
    "\n",
    "    print(f\"--- Workflow Transition: Prompt Enhancer → Supervisor ---\")\n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [  \n",
    "                HumanMessage(\n",
    "                    content=enhanced_query.content, \n",
    "                    name=\"enhancer\"  \n",
    "                )\n",
    "            ]\n",
    "        },\n",
    "        goto=\"supervisor\", \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def research_node(state: MessagesState) -> Command[Literal[\"validator\"]]:\n",
    "\n",
    "    \"\"\"\n",
    "        Research agent node that gathers information using Tavily search.\n",
    "        Takes the current task state, performs relevant research,\n",
    "        and returns findings for validation.\n",
    "    \"\"\"\n",
    "    \n",
    "    research_agent = create_react_agent(\n",
    "        llm,  \n",
    "        tools=[tavily_search],  \n",
    "        state_modifier= \"You are an Information Specialist with expertise in comprehensive research. Your responsibilities include:\\n\\n\"\n",
    "            \"1. Identifying key information needs based on the query context\\n\"\n",
    "            \"2. Gathering relevant, accurate, and up-to-date information from reliable sources\\n\"\n",
    "            \"3. Organizing findings in a structured, easily digestible format\\n\"\n",
    "            \"4. Citing sources when possible to establish credibility\\n\"\n",
    "            \"5. Focusing exclusively on information gathering - avoid analysis or implementation\\n\\n\"\n",
    "            \"Provide thorough, factual responses without speculation where information is unavailable.\"\n",
    "    )\n",
    "\n",
    "    result = research_agent.invoke(state)\n",
    "\n",
    "    print(f\"--- Workflow Transition: Researcher → Validator ---\")\n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [ \n",
    "                HumanMessage(\n",
    "                    content=result[\"messages\"][-1].content,  \n",
    "                    name=\"researcher\"  \n",
    "                )\n",
    "            ]\n",
    "        },\n",
    "        goto=\"validator\", \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_node(state: MessagesState) -> Command[Literal[\"validator\"]]:\n",
    "\n",
    "    code_agent = create_react_agent(\n",
    "        llm,\n",
    "        tools=[python_repl_tool],\n",
    "        state_modifier=(\n",
    "            \"You are a coder and analyst. Focus on mathematical calculations, analyzing, solving math questions, \"\n",
    "            \"and executing code. Handle technical problem-solving and data tasks.\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    result = code_agent.invoke(state)\n",
    "\n",
    "    print(f\"--- Workflow Transition: Coder → Validator ---\")\n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"coder\")\n",
    "            ]\n",
    "        },\n",
    "        goto=\"validator\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System prompt providing clear instructions to the validator agent\n",
    "system_prompt = '''\n",
    "    Your task is to ensure reasonable quality. \n",
    "    Specifically, you must:\n",
    "    - Review the user's question (the first message in the workflow).\n",
    "    - Review the answer (the last message in the workflow).\n",
    "    - If the answer addresses the core intent of the question, even if not perfectly, signal to end the workflow with 'FINISH'.\n",
    "    - Only route back to the supervisor if the answer is completely off-topic, harmful, or fundamentally misunderstands the question.\n",
    "    \n",
    "    - Accept answers that are \"good enough\" rather than perfect\n",
    "    - Prioritize workflow completion over perfect responses\n",
    "    - Give benefit of doubt to borderline answers\n",
    "    \n",
    "    Routing Guidelines:\n",
    "    1. 'supervisor' Agent: ONLY for responses that are completely incorrect or off-topic.\n",
    "    2. Respond with 'FINISH' in all other cases to end the workflow.\n",
    "'''\n",
    "\n",
    "class Validator(BaseModel):\n",
    "    next: Literal[\"supervisor\", \"FINISH\"] = Field(\n",
    "        description=\"Specifies the next worker in the pipeline: 'supervisor' to continue or 'FINISH' to terminate.\"\n",
    "    )\n",
    "    reason: str = Field(\n",
    "        description=\"The reason for the decision.\"\n",
    "    )\n",
    "\n",
    "def validator_node(state: MessagesState) -> Command[Literal[\"supervisor\", \"__end__\"]]:\n",
    "\n",
    "    user_question = state[\"messages\"][0].content\n",
    "    agent_answer = state[\"messages\"][-1].content\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_question},\n",
    "        {\"role\": \"assistant\", \"content\": agent_answer},\n",
    "    ]\n",
    "\n",
    "    response = llm.with_structured_output(Validator).invoke(messages)\n",
    "\n",
    "    goto = response.next\n",
    "    reason = response.reason\n",
    "\n",
    "    if goto == \"FINISH\" or goto == END:\n",
    "        goto = END  \n",
    "        print(\" --- Transitioning to END ---\")  \n",
    "    else:\n",
    "        print(f\"--- Workflow Transition: Validator → Supervisor ---\")\n",
    " \n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=reason, name=\"validator\")\n",
    "            ]\n",
    "        },\n",
    "        goto=goto, \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(MessagesState)\n",
    "\n",
    "graph.add_node(\"supervisor\", supervisor_node) \n",
    "graph.add_node(\"enhancer\", enhancer_node)  \n",
    "graph.add_node(\"researcher\", research_node) \n",
    "graph.add_node(\"coder\", code_node) \n",
    "graph.add_node(\"validator\", validator_node)  \n",
    "\n",
    "graph.add_edge(START, \"supervisor\")  \n",
    "app = graph.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Workflow Transition: Supervisor → ENHANCER ---\n",
      "\"Output from node 'supervisor':\"\n",
      "HumanMessage(content=\"The user's request 'Weather in Chennai' is quite vague. It lacks specificity regarding the type of weather information needed (e.g., current weather, forecast, historical data, etc.). Sending this to the Prompt Enhancer will help clarify the user's intent and refine the query, facilitating a more targeted response in subsequent steps.\", additional_kwargs={}, response_metadata={}, name='supervisor', id='2b8343b3-c3bb-4b5e-9ea8-3afe2e8bb64e')\n",
      "\n",
      "--- Workflow Transition: Prompt Enhancer → Supervisor ---\n",
      "\"Output from node 'enhancer':\"\n",
      "HumanMessage(content='Provide a detailed weather report for Chennai, including the current temperature, humidity, wind speed, and any significant weather conditions. Additionally, include a short-term weather forecast for the next five days, highlighting potential changes in temperature, precipitation, or severe weather alerts. Define any technical terms such as \"humidity\" or \"wind speed\" in context to ensure clarity.', additional_kwargs={}, response_metadata={}, name='enhancer', id='cdbfb243-8895-402a-af5b-8220c6302027')\n",
      "\n",
      "--- Workflow Transition: Supervisor → RESEARCHER ---\n",
      "\"Output from node 'supervisor':\"\n",
      "HumanMessage(content='The enhanced prompt now specifically requests current weather conditions and a short-term forecast for Chennai, along with explanations of any key terms. The Researcher is the most suitable next agent to gather accurate and up-to-date weather data, as well as forecast information, to address this request comprehensively.', additional_kwargs={}, response_metadata={}, name='supervisor', id='cb68f9fd-2fc2-4811-971f-51a65dfa42d1')\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "create_react_agent() got unexpected keyword arguments: {'state_modifier': 'You are an Information Specialist with expertise in comprehensive research. Your responsibilities include:\\n\\n1. Identifying key information needs based on the query context\\n2. Gathering relevant, accurate, and up-to-date information from reliable sources\\n3. Organizing findings in a structured, easily digestible format\\n4. Citing sources when possible to establish credibility\\n5. Focusing exclusively on information gathering - avoid analysis or implementation\\n\\nProvide thorough, factual responses without speculation where information is unavailable.'}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpprint\u001b[39;00m\n\u001b[32m      3\u001b[39m inputs = {\n\u001b[32m      4\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m      5\u001b[39m         (\u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mWeather in Chennai\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m      6\u001b[39m     ]\n\u001b[32m      7\u001b[39m }\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mapp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/langgraph-mini-course/.venv/lib/python3.11/site-packages/langgraph/pregel/main.py:2647\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2645\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2646\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2647\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2648\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2649\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2650\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2651\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2652\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2653\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2654\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2657\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/langgraph-mini-course/.venv/lib/python3.11/site-packages/langgraph/pregel/_runner.py:162\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    160\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/langgraph-mini-course/.venv/lib/python3.11/site-packages/langgraph/pregel/_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/langgraph-mini-course/.venv/lib/python3.11/site-packages/langgraph/_internal/_runnable.py:657\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    655\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    656\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m657\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    659\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/langgraph-mini-course/.venv/lib/python3.11/site-packages/langgraph/_internal/_runnable.py:401\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    399\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    403\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mresearch_node\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mresearch_node\u001b[39m(state: MessagesState) -> Command[Literal[\u001b[33m\"\u001b[39m\u001b[33mvalidator\u001b[39m\u001b[33m\"\u001b[39m]]:\n\u001b[32m      3\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m        Research agent node that gathers information using Tavily search.\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33;03m        Takes the current task state, performs relevant research,\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[33;03m        and returns findings for validation.\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     research_agent = \u001b[43mcreate_react_agent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtavily_search\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_modifier\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mYou are an Information Specialist with expertise in comprehensive research. Your responsibilities include:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     13\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m1. Identifying key information needs based on the query context\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     14\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m2. Gathering relevant, accurate, and up-to-date information from reliable sources\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     15\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m3. Organizing findings in a structured, easily digestible format\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     16\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m4. Citing sources when possible to establish credibility\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     17\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m5. Focusing exclusively on information gathering - avoid analysis or implementation\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     18\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mProvide thorough, factual responses without speculation where information is unavailable.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m     result = research_agent.invoke(state)\n\u001b[32m     23\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m--- Workflow Transition: Researcher → Validator ---\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/langgraph-mini-course/.venv/lib/python3.11/site-packages/langgraph/prebuilt/chat_agent_executor.py:477\u001b[39m, in \u001b[36mcreate_react_agent\u001b[39m\u001b[34m(model, tools, prompt, response_format, pre_model_hook, post_model_hook, state_schema, context_schema, checkpointer, store, interrupt_before, interrupt_after, debug, version, name, **deprecated_kwargs)\u001b[39m\n\u001b[32m    474\u001b[39m         context_schema = config_schema\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(deprecated_kwargs) > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    478\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mcreate_react_agent() got unexpected keyword arguments: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdeprecated_kwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    479\u001b[39m     )\n\u001b[32m    481\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m version \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33mv1\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mv2\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    482\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    483\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid version \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mversion\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Supported versions are \u001b[39m\u001b[33m'\u001b[39m\u001b[33mv1\u001b[39m\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[33m'\u001b[39m\u001b[33mv2\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    484\u001b[39m     )\n",
      "\u001b[31mTypeError\u001b[39m: create_react_agent() got unexpected keyword arguments: {'state_modifier': 'You are an Information Specialist with expertise in comprehensive research. Your responsibilities include:\\n\\n1. Identifying key information needs based on the query context\\n2. Gathering relevant, accurate, and up-to-date information from reliable sources\\n3. Organizing findings in a structured, easily digestible format\\n4. Citing sources when possible to establish credibility\\n5. Focusing exclusively on information gathering - avoid analysis or implementation\\n\\nProvide thorough, factual responses without speculation where information is unavailable.'}",
      "During task with name 'researcher' and id 'ac814c31-db26-26ad-c480-7bbf32787aed'"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "inputs = {\n",
    "    \"messages\": [\n",
    "        (\"user\", \"Weather in Sao Paulo\"),\n",
    "    ]\n",
    "}\n",
    "\n",
    "for event in app.stream(inputs):\n",
    "    for key, value in event.items():\n",
    "        if value is None:\n",
    "            continue\n",
    "        last_message = value.get(\"messages\", [])[-1] if \"messages\" in value else None\n",
    "        if last_message:\n",
    "            pprint.pprint(f\"Output from node '{key}':\")\n",
    "            pprint.pprint(last_message, indent=2, width=80, depth=None)\n",
    "            print()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Workflow Transition: Supervisor → CODER ---\n",
      "\"Output from node 'supervisor':\"\n",
      "{ 'messages': [ HumanMessage(content='The user is requesting a specific numerical result from a well-defined sequence, the Fibonacci sequence, which is best served by calculating the value using a coding implementation. The problem is clear and structured, making it appropriate to move directly to the Coder for computation.', additional_kwargs={}, response_metadata={}, name='supervisor', id='87be29a9-57af-4c6d-b5c1-a8247818b65b')]}\n",
      "\n",
      "--- Workflow Transition: Coder → Validator ---\n",
      "\"Output from node 'coder':\"\n",
      "{ 'messages': [ HumanMessage(content='The 20th Fibonacci number is 6765.', additional_kwargs={}, response_metadata={}, name='coder', id='dfedec00-14f1-413e-9ee3-72257b362f5d')]}\n",
      "\n",
      " --- Transitioning to END ---\n",
      "\"Output from node 'validator':\"\n",
      "{ 'messages': [ HumanMessage(content=\"The answer correctly identifies the 20th Fibonacci number, addressing the user's request.\", additional_kwargs={}, response_metadata={}, name='validator', id='fdd556cd-0b42-41a6-83b4-7ee4e3663e2e')]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "inputs = {\n",
    "    \"messages\": [\n",
    "        (\"user\", \"Give me the 20th fibonacci number\"),\n",
    "    ]\n",
    "}\n",
    "for event in app.stream(inputs):\n",
    "    for key, value in event.items():\n",
    "        if value is None:\n",
    "            continue\n",
    "        pprint.pprint(f\"Output from node '{key}':\")\n",
    "        pprint.pprint(value, indent=2, width=80, depth=None)\n",
    "        print()\n",
    "     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
